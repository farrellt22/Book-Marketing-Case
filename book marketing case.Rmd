---
title: "Book case study"
author: "Thomas Farrell, Leo Salazar, Mia Brito, Raneen Aljamal, Adrian Joshua"
date: "2/28/2022"
output: 
  pdf_document:
    toc: true
    
    
bibliography: citations.bib
---


\newpage

## Executive Summary

|       The Bookbinders club is a distribution company that sells specialty books through direct marketing. There are three types of predictive modeling used within this case to determine which customers the company should target for their next direct marketing campaign. The models utilized are Linear Regression, Logistic Regression, and Support Vector Machines. The results of the study show that the logistic regression model was the most accurate at predicting which customers would make a purchase with a sensitivity of 73%. When compared to the Support Vector machine model we only achieved a sensitivity of 28.5%. The most significant predictor variables found in the Logistic regression model were Gender, Time period since last purchase and their frequency.

## The Problem

|       BBBC is exploring whether to use predictive modeling approaches to improve the efficacy of its direct mail program. For a recent mailing, the company selected 20,000 customers in Pennsylvania, New York, and Ohio from its database and included with their regular mailing a specially produced brochure for the book The Art History of Florence. This resulted in a 9.03% response rate (1806 orders) for the purchase of the book. BBBC then developed a database to calibrate a response model to identify the factors that influences these purchases.  For this case analysis, we will use a subset of the database available to BBBC. It consists of data for 400 customers who purchased the book and 1200 customers who did not, thereby overrepresenting the response group. The dependent variable for the analysis is Choice – purchase or no purchase of the book. BBBC also selected several independent variables that it thought might explain the observed choice behavior. 
	In this study we explored the variables that would be most significant to accurately predict who would purchase a book or not. We used the Linear Regression. Logit model, and Support Vector Machine to analyze the data.



## Related Literature

|       In the previous case study, we explored that Mitchell Dayton concluded that logistical regression analysis is often described as the response variable, which must be of numerical value. In this case study, we wanted to explore the use of linear regression. According to ---, linear regression and logistic regression have many similarities. However, there are a few differences. For example, linear regression more commonly handles regression problems while logistic regression tackles the process of classifying problems. 
 
|       In Kyung-Shik Shin, Taik Soo Lee, and Hyun-jung Kim’s case study An Application of Support Vector Machines in Bankruptcy Prediction Model, they explored the use of support vector machines in a Bankruptcy Prediction Model. As Noel Bambrick, a Support Vector Machines helps with classification and regression through a machine learning algorithm. It uses the notion of finding a hyperplane to divide data into two groups. In Shin, Lee, and Kim’s case of corporate bankruptcy prediction, the Support Vector Model method is more effective than the Back-Propagation Neural Network method. The Support Vector Model proved to be more accurate and have better performance. Therefore, we wanted to explore the use of SVMs in our case study. 
 
|       In addition to SVMs and linear regression, in this case study we will also explore the use of Logit Models. A Logit Regression Model is essentially the generalized linear model when discussing its link function. It is commonly compared to the logistical regression model, however, the logistic regression is the generalized linear model when discussing its activation function. In this case study, we explored the use of linear regression, support vector model, and a logit model to evaluate which variable would be most significant when predicting who would purchase a book. 

\newpage
## Methodology

  choice: whether the customer purchased the art history of Florence. 
  1- represents a purchase
  0- representa a nonpurchase
  
Gender: 0 = Female , 1 = Male
Amount_Purchased - Total money spent on BBBC books

Frequency: Total number of purchases in the chosen period 

Last_Purchase: Months since last purchase

First_Purchase: Months since first purchase

P_Child: Number of children's books purchased

P_Youth: Number of youth books purchased

P_Cook: Number of cookbooks purchased

P_DIY: Number of do-it-yourself books purchased

P_Art: Number of art books purchased


## Loading libraries


```{r message=FALSE}

library(readxl)
library(e1071)
library(caret)
library(ROCR)
library(ggplot2)
library(tidyverse)
library(MASS)
library(ggThemeAssist)
library(esquisse)
library(gridExtra)
library(trackdown)
library(corrplot)
source('/Users/thomasfarrell/Downloads/optim_threshold.R')
```





## Load in data

```{r pressure}
bbtrain = read_excel("/Users/thomasfarrell/Downloads/BBBC-Train.xlsx")
bbtest = read_excel("/Users/thomasfarrell/Downloads/BBBC-Test.xlsx")
```



## Checking for any missing values

```{r}
colSums(is.na(bbtest))
```


## Remove first column is data
We remove the first variable in the data due to the fact that this column just held a placeholder number.
```{r}
bbtrain = bbtrain[-c(1)]
bbtest = bbtest[-c(1)]
```


## Convert the response variable to a factor

```{r}
bbtrain$Choice = as.factor(bbtrain$Choice)
bbtest$Choice = as.factor(bbtest$Choice)
```



## Checking correlation within X-Variables

```{r}
b1_num = dplyr::select_if(bbtrain, is.numeric)
M = cor(b1_num)
corrplot(M, method = "number")

cor(bbtrain[sapply(bbtrain, is.numeric)])
```


Highest correlations are between First_purchase and Last_purchase, which makes sense in a way. An only customer makes a purchase and walks out, that may be both a First purchase and Last purchase observation. Repeat customers will have a longer time in months for their first First purchase than their Last purchase. 

[@art1][@art2][@art3][@art4]
## Exploratory Analysis

```{r}
p1 = ggplot(data = bbtrain, mapping = aes(x = Frequency, fill = Choice))+
  geom_histogram() + theme(plot.title = element_text(face = "italic"),
    panel.background = element_rect(fill = "gray90",
        colour = "antiquewhite1", linetype = "dotted"),
    plot.background = element_rect(fill = "white",
        linetype = "dashed"))



```



```{r}

p2 = ggplot(bbtrain) +
  aes(x = Last_purchase, fill = Choice) +
  geom_histogram(bins = 30L) +
  scale_fill_hue(direction = 1) +
  theme_minimal()
```

```{r}
p3 = ggplot(bbtrain) +
  aes(x = P_Child, fill = Choice) +
  geom_histogram(bins = 30L) +
  scale_fill_hue(direction = 1) +
  theme_minimal()
```



```{r}
p4 = ggplot(bbtrain) +
  aes(x = Amount_purchased, fill = Choice) +
  geom_histogram(bins = 30L) +
  scale_fill_hue(direction = 1) +
  theme_minimal()
```




```{r}
grid.arrange(p1,p2,p3,p4)
```






```{r}
par(mfrow = c(3,3))
hist(bbtrain$Amount_purchased, xlab = "Amount Purchased", main = "Amount Purchased")
hist(bbtrain$Frequency, xlab = "Total Num. Purchased", main = "Total Purchased")
hist(bbtrain$Last_purchase, xlab = "Months Since Last Purchase", main = "Last Purchase")
hist(bbtrain$First_purchase, xlab = "Months Since First Purchase", main = "First Purchase")
hist(bbtrain$P_Child, xlab = "No. Children's Books Purchased", main = "Children's Books")
hist(bbtrain$P_Youth, xlab = "No. Youth Books Purchased", main = "Youth Books")
hist(bbtrain$P_Cook, xlab = "No. Cook Books Purchased", main = "Cook Books")
hist(bbtrain$P_DIY, xlab = "No. DIY Books Purchased", main = "DIY Books")
hist(bbtrain$P_Art, xlab = "No. Art Books Purchased", main = "Art Books")
```


From these charts we can see that the Amount Purchased variable is the only variable that looks normally distributed and they other variables appear to have a right skew in their results.

\newpage

## Results and findings

|       The three modeling methods that we used were a linear regression model, a logit model (glm), and a support vector machine (SVM). The accuracy and sensitivity for each of the techniques vary, as well as the confusion matrices that tell us what each model predicts the best. However, the linear regression model would not be appropriate to use in this instance because a linear model can only be applied when using a continuous dependent variable, rather than a binary one that uses 0 and 1’s. Logistic regression is typically used when the objective of the prediction is to project an outcome variable versus seeing how every predictor variable is related to the outcome variable. 


## Linear model

```{r}
par(mfrow=c(2,2))
mod_1 = lm(as.numeric(Choice) ~., data = bbtrain)
plot(mod_1)
```

\newpage

*	Advantages:	
    * Simple Explanation
    * Linear regression fits linearly separable data sets almost perfectly and is often used to find the nature of the relationship between variables. 
    * Overfitting of data can reduced by regularization.

*	Disadvantages: 
    * Prone to under fitting
    * Sensitive to outliers
    * Does not work well with categorical variables as the dependent (unless given a scaled value).
Assumes the information is independent


```{r}
summary(mod_1)
```

#VIF for linear model

```{r}
car::vif(mod_1)
```

Last_Purchase and First_Purchase have a GVIF over 5 which tells us that we must remove these variables due to multiculinarity.


```{r}
bbtrain = dplyr::select(bbtrain, - Last_purchase)
bbtrain = dplyr::select(bbtrain, - First_purchase)
```

```{r}
mod_1 = lm(as.numeric(Choice) ~., data = bbtrain)
car::vif(mod_1)
```

Our new model has improved as all our variables are under 5 GVIF.

\newpage

## Logit model

```{r}
glm.fit = glm(Choice ~ ., data = bbtrain, family = binomial)
summary(glm.fit)

glm2.fit = step(glm.fit,direction = "backward")
summary(glm2.fit)
car::vif(glm2.fit)
```


*	Advantages:	
    * Relatively easy to interpret and allows a clear understanding of how each of the predictors are influencing the outcome.
    * We do not need to transform the response to have a normal distribution.
    * Able to deal with categorical predictors.

*	Disadvantages: 
    * Predictor variables need to be uncorrelated.
    * Strict assumptions around distribution shape and randomness of error terms.
    * Sensitive to outliers





### finding the optimal threshold


```{r}
optim_threshold(glm2.fit,bbtest, bbtest$Choice)
```





```{r}
predprob = predict.glm(glm2.fit, newdata = bbtest, type = "response")
predict.glm = ifelse(predprob >= .23, 1, 0)
caret::confusionMatrix(as.factor(predict.glm), as.factor(bbtest$Choice), positive = '1')
```


\newpage

## SVM Model



### Tuning the SVM Model


```{r}
set.seed(1)
tuned = tune.svm(Choice ~ ., data = bbtrain, kernel = 'linear',gamma = seq(.01,.1,by = .025), cost = seq(.1,1.2, by = .1), scale = TRUE)
tuned$best.parameters

```

*	Advantages:	
    * It works really well with a clear margin of separation
    * It is effective in cases where the number of dimensions is greater than the number of samples
    * It uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.

*	Disadvantages: 
    * It doesn’t perform well when we have large data set because the required training time is higher
    * SVM doesn’t directly provide probability estimates, these are calculated using an expensive five-fold cross-validation
    * It also doesn’t perform very well, when the data set has more noise i.e. target classes are overlapping



#creating SVM using tuned parameters

```{r}
svm1 = svm(Choice ~ ., data = bbtrain, kernel = 'linear', gamma = tuned$best.parameters$gamma, cost = tuned$best.parameters$cost)

```




#Make predictions on training data set

```{r}
predSVM = predict(svm1, bbtrain)
caret::confusionMatrix(predSVM, bbtrain$Choice, positive = "1")
```

The accuracy of our tuned model is 79.19% with a sensitivity of .285 and specificity of .96.


#make prediticions on the testing data set

```{r}
predSVM = predict(svm1, bbtest)
caret::confusionMatrix(predSVM, bbtest$Choice, positive = "1")
```

With our tuned model against the testing data our model achieves an accuracy of 90.13% and a sensitivity of .279 and specificity of .961.

\newpage
## Conclusions and recommendations

|       After evaluating all three models, we concluded that the SVM was best at predicting which customers did not purchase a book, however it did not accurately predict the customers who did purchase a book. This is shown through the confusion matrix of the testing data set, where the SVM confusion matrix predicted a large number of true negatives and a specificity of 96.1% and sensitivity of 27.9% with an overall accuracy of 90.1%. 
|       The logistic regression model best predicted a balance between who did purchase a book and who did not. The sensitivity of the logistic regression model was 73%, the specificity was 71%, and the accuracy was 71.2%. From this information, we see that the proportion of the predictions are more accurate at choosing which respondents would purchase a book or not. 
|       There are two different methods to try to balance the data. The first method is to take a smaller sample of the data with more even yes and no results. Then we could run a logistic regression to produce a more accurate model with similar specificity and sensitivity numbers. To make a more accurate SVM model would could use a weighted SVM model, which would assign weights to the dependent variable classes. The differences in weights will influence the classification outcome during the training phase.



\newpage
## References


